{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tg.datasets import DatasetFactoryLookupCallback\n",
    "from tg.model_interactor import ModelInteractor\n",
    "from tg.splitters import AnchoredSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'NOISY_SINE30'\n",
    "data_factory = DatasetFactoryLookupCallback(dataset_name=dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'ES_LSTM'\n",
    "params = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/40 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'ExponentialSmoothingModel' object has no attribute 'predict_residuals'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [5], line 16\u001b[0m\n\u001b[0;32m      4\u001b[0m mi\u001b[39m.\u001b[39mload(y\u001b[39m=\u001b[39my,\n\u001b[0;32m      5\u001b[0m         X\u001b[39m=\u001b[39mX,\n\u001b[0;32m      6\u001b[0m         dataset_name\u001b[39m=\u001b[39mdata_factory\u001b[39m.\u001b[39mdataset_name,\n\u001b[0;32m      7\u001b[0m         timesteps\u001b[39m=\u001b[39mdata_factory\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39mperiod,\n\u001b[0;32m      8\u001b[0m         train_size\u001b[39m=\u001b[39mdata_factory\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39mtrain_size)\n\u001b[0;32m     10\u001b[0m trains, test \u001b[39m=\u001b[39m mi\u001b[39m.\u001b[39msplit_trains_test(\n\u001b[0;32m     11\u001b[0m     y\u001b[39m=\u001b[39mmi\u001b[39m.\u001b[39my,\n\u001b[0;32m     12\u001b[0m     splitter_class\u001b[39m=\u001b[39mAnchoredSplitter,\n\u001b[0;32m     13\u001b[0m     splitter_args\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39mmin_train_points\u001b[39m\u001b[39m'\u001b[39m: data_factory\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39mtrain_size},\n\u001b[0;32m     14\u001b[0m     X\u001b[39m=\u001b[39mmi\u001b[39m.\u001b[39mX)\n\u001b[1;32m---> 16\u001b[0m preds \u001b[39m=\u001b[39m mi\u001b[39m.\u001b[39;49mfit_predict(trains\u001b[39m=\u001b[39;49mtrains, test\u001b[39m=\u001b[39;49mtest, parameters\u001b[39m=\u001b[39;49mparams)\n\u001b[0;32m     17\u001b[0m metrics \u001b[39m=\u001b[39m mi\u001b[39m.\u001b[39mevaluate(preds\u001b[39m=\u001b[39mpreds, test\u001b[39m=\u001b[39mtest)\n",
      "File \u001b[1;32m~\\Documents\\Github\\tg\\src\\tg\\model_interactor.py:88\u001b[0m, in \u001b[0;36mModelInteractor.fit_predict\u001b[1;34m(self, trains, test, parameters)\u001b[0m\n\u001b[0;32m     86\u001b[0m         preds\u001b[39m.\u001b[39mappend(partial_predict(y\u001b[39m=\u001b[39mtrain[\u001b[39m0\u001b[39m], X\u001b[39m=\u001b[39mtrain[\u001b[39m1\u001b[39m]))\n\u001b[0;32m     87\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 88\u001b[0m         preds\u001b[39m.\u001b[39mappend(partial_predict(y\u001b[39m=\u001b[39;49mtrain))\n\u001b[0;32m     90\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_class\u001b[39m.\u001b[39minstance\u001b[39m.\u001b[39msingle_input:\n\u001b[0;32m     91\u001b[0m     \u001b[39mreturn\u001b[39;00m pd\u001b[39m.\u001b[39mSeries(preds, index\u001b[39m=\u001b[39mtest[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mindex, name\u001b[39m=\u001b[39mtest[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mname)\n",
      "File \u001b[1;32m~\\Documents\\Github\\tg\\src\\tg\\model_interactor.py:208\u001b[0m, in \u001b[0;36mModelInteractor._fit_predict\u001b[1;34m(self, parameters, y, X)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_fit_predict\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[0;32m    204\u001b[0m                  parameters: \u001b[39mdict\u001b[39m,\n\u001b[0;32m    205\u001b[0m                  y: pd\u001b[39m.\u001b[39mSeries,\n\u001b[0;32m    206\u001b[0m                  X: pd\u001b[39m.\u001b[39mDataFrame \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mfloat\u001b[39m:\n\u001b[0;32m    207\u001b[0m     model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_class(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparameters)\n\u001b[1;32m--> 208\u001b[0m     model\u001b[39m.\u001b[39;49mfit(y, X, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimesteps)\n\u001b[0;32m    209\u001b[0m     \u001b[39mreturn\u001b[39;00m model\u001b[39m.\u001b[39mpredict_one_ahead()\n",
      "File \u001b[1;32m~\\Documents\\Github\\tg\\src\\tg\\models.py:666\u001b[0m, in \u001b[0;36mESLSTMModel.fit\u001b[1;34m(self, y, X, timesteps)\u001b[0m\n\u001b[0;32m    662\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[0;32m    663\u001b[0m         y: pd\u001b[39m.\u001b[39mSeries,\n\u001b[0;32m    664\u001b[0m         X: pd\u001b[39m.\u001b[39mDataFrame \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    665\u001b[0m         timesteps: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 666\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(y\u001b[39m=\u001b[39;49my, X\u001b[39m=\u001b[39;49mX, timesteps\u001b[39m=\u001b[39;49mtimesteps)\n",
      "File \u001b[1;32m~\\Documents\\Github\\tg\\src\\tg\\model_interfaces.py:60\u001b[0m, in \u001b[0;36mHybridModel.fit\u001b[1;34m(self, y, X, timesteps)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmethod \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mresidue\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m     59\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfirst_model\u001b[39m.\u001b[39mfit(y\u001b[39m=\u001b[39my, X\u001b[39m=\u001b[39mX, timesteps\u001b[39m=\u001b[39mtimesteps)\n\u001b[1;32m---> 60\u001b[0m     first_model_residuals \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfirst_model\u001b[39m.\u001b[39;49mpredict_residuals()[\u001b[39m1\u001b[39m:]\n\u001b[0;32m     61\u001b[0m     y_residuals \u001b[39m=\u001b[39m stack_lags(first_model_residuals, timesteps)\n\u001b[0;32m     62\u001b[0m     y_lagged \u001b[39m=\u001b[39m stack_lags(y[\u001b[39m1\u001b[39m:], timesteps)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ExponentialSmoothingModel' object has no attribute 'predict_residuals'"
     ]
    }
   ],
   "source": [
    "y, X = data_factory(model_name=model_name)\n",
    "\n",
    "mi = ModelInteractor(model_name=model_name)\n",
    "mi.load(y=y,\n",
    "        X=X,\n",
    "        dataset_name=data_factory.dataset_name,\n",
    "        timesteps=data_factory.dataset.period,\n",
    "        train_size=data_factory.dataset.train_size)\n",
    "\n",
    "trains, test = mi.split_trains_test(\n",
    "    y=mi.y,\n",
    "    splitter_class=AnchoredSplitter,\n",
    "    splitter_args={'min_train_points': data_factory.dataset.train_size},\n",
    "    X=mi.X)\n",
    "\n",
    "preds = mi.fit_predict(trains=trains, test=test, parameters=params)\n",
    "metrics = mi.evaluate(preds=preds, test=test)\n",
    "\n",
    "# mi.execute_mlflow(\n",
    "#     splitter_class=AnchoredSplitter,\n",
    "#     splitter_args={'min_train_points': data_factory.dataset.train_size},\n",
    "#     parameters={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "ax.plot(y, label='y')\n",
    "ax.plot(preds, label='preds')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mi.tune_hyperparameters(\n",
    "#     splitter_class=AnchoredSplitter,\n",
    "#     splitter_args={'min_train_points': data_factory.dataset.tuning_train_size},\n",
    "#     n_trials=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mi.get_best_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3cc4cab7a7dac5d65e85e0eebf2661a2d2db91ed47d95bc0e6be69046fbc8142"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
