{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tg.datasets import DatasetFactoryLookupCallback\n",
    "from tg.interactors import ModelInteractor\n",
    "from tg.splitters import AnchoredSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'AIR_PASSENGERS'\n",
    "\n",
    "data_factory = DatasetFactoryLookupCallback(dataset_name=dataset_name)\n",
    "\n",
    "# model_name = 'ARIMA_RNN'\n",
    "# params = {'epochs': 100, 'hidden_units': 15}\n",
    "\n",
    "model_name = 'SVR'\n",
    "params = {'C': 0.1, 'epsilon': 0.1, 'kernel': 'rbf'}\n",
    "\n",
    "# model_name = 'SARIMA_SVR'\n",
    "# params = {\n",
    "#     'm': data_factory.dataset.period,\n",
    "#     'C': 0.1,\n",
    "#     'epsilon': 0.1,\n",
    "#     'kernel': 'rbf'\n",
    "# }\n",
    "\n",
    "y, X = data_factory(model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:00<00:00, 771.28it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rmse': 208.29904413232765,\n",
       " 'smape': 26.358503878941008,\n",
       " 'mape': 41.27497671922652,\n",
       " 'mae': 196.08905714495032}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi = ModelInteractor(model_name=model_name)\n",
    "mi.load(y=y,\n",
    "        X=X,\n",
    "        dataset_name=data_factory.dataset_name,\n",
    "        timesteps=data_factory.dataset.period,\n",
    "        train_size=data_factory.dataset.train_size)\n",
    "\n",
    "# trains, test = mi.split_trains_test(\n",
    "#     y=y,\n",
    "#     X=X,\n",
    "#     splitter_class=AnchoredSplitter,\n",
    "#     splitter_args={'min_train_points': data_factory.dataset.train_size})\n",
    "# preds = mi.fit_predict(trains=trains, test=test, parameters=params)\n",
    "# metrics = mi.evaluate(preds=preds, test=test)\n",
    "\n",
    "# best_params = mi.tune_hyperparameters(\n",
    "#     splitter_class=AnchoredSplitter,\n",
    "#     splitter_args={'min_train_points': data_factory.dataset.tuning_train_size},\n",
    "#     n_trials=2)\n",
    "\n",
    "mi.execute_mlflow(\n",
    "    splitter_class=AnchoredSplitter,\n",
    "    splitter_args={'min_train_points': data_factory.dataset.train_size},\n",
    "    parameters=params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    'NAIVE',\n",
    "    'ARIMA',\n",
    "    'SARIMA',\n",
    "    'RNN',\n",
    "    'SVR',\n",
    "    'ARIMA_RNN',\n",
    "    'SARIMA_SVR',\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3cc4cab7a7dac5d65e85e0eebf2661a2d2db91ed47d95bc0e6be69046fbc8142"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
