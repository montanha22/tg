{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from multiprocessing import Pool\n",
    "from typing import Callable, List, Tuple, Type, Dict\n",
    "from uuid import uuid4\n",
    "\n",
    "import mlflow\n",
    "import optuna\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import keras\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "import pmdarima as pm\n",
    "\n",
    "from src import metrics, models\n",
    "from src.datasets import DATASET_FACTORY_LOOKUP\n",
    "from src.splitters import AnchoredSplitter, Splitter\n",
    "from src.ts_models import ModelClassLookupCallback\n",
    "from src.ts_models import SARIMAModel, RNNModel\n",
    "from src.hybrid_model import HybridModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SARIMAModel:\n",
    "\n",
    "    def __init__(self, m: int):\n",
    "        self.m = m\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, y: pd.Series) -> None:\n",
    "        self.model = pm.auto_arima(y, seasonal=True, m=self.m)\n",
    "\n",
    "    def predict_one_ahead(self) -> float:\n",
    "        return self.model.predict(n_periods=1)[0]\n",
    "\n",
    "    @staticmethod\n",
    "    def suggest_params(trial: optuna.Trial) -> Dict[str, int]:\n",
    "        return {}\n",
    "\n",
    "\n",
    "class RNNModel:\n",
    "\n",
    "    def __init__(self,\n",
    "                 timesteps: int,\n",
    "                 hidden_units: int,\n",
    "                 epochs: int,\n",
    "                 m: int = None):\n",
    "        self.timesteps = timesteps\n",
    "        self.hidden_units = hidden_units\n",
    "        self.epochs = epochs\n",
    "\n",
    "    def _create_model(self) -> keras.Sequential:\n",
    "        model = keras.Sequential()\n",
    "        model.add(\n",
    "            layers.SimpleRNN(\n",
    "                units=self.hidden_units,\n",
    "                activation=\"relu\",\n",
    "                input_shape=(self.timesteps, 1),\n",
    "            ))\n",
    "        model.add(layers.Dense(1))\n",
    "        model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "        return model\n",
    "\n",
    "    def fit(self, y: pd.Series, X: pd.DataFrame) -> None:\n",
    "\n",
    "        y = y.values\n",
    "        X = X.values.reshape(X.shape[0], self.timesteps, 1)\n",
    "\n",
    "        self.model = self._create_model()\n",
    "        self.model.fit(X, y, epochs=self.epochs, verbose=0)\n",
    "\n",
    "    def predict_one_ahead(self, X:pd.DataFrame) -> float:\n",
    "        if hasattr(self, \"model\"):\n",
    "            return self.model.predict(X.values.reshape(1, self.timesteps, 1))[0][0]\n",
    "\n",
    "    @staticmethod\n",
    "    def suggest_params(trial: optuna.Trial) -> dict:\n",
    "        timesteps = trial.suggest_categorical(\"timesteps\",\n",
    "                                              [2, 4, 6, 12, 24, 36])\n",
    "        hidden_units = trial.suggest_int(\"hidden_units\", 5, 25, 5)\n",
    "        epochs = trial.suggest_int(\"epochs\", 300, 800, 100)\n",
    "\n",
    "        return {\n",
    "            \"timesteps\": timesteps,\n",
    "            \"hidden_units\": hidden_units,\n",
    "            \"epochs\": epochs\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearModelInteractor:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_trains_test(\n",
    "    y: pd.Series,\n",
    "    splitter: Splitter,\n",
    ") -> Tuple[List[pd.Series], pd.Series]:\n",
    "\n",
    "    slices = splitter.split(y)\n",
    "\n",
    "    train_indexes_list = [s[0] for s in slices]\n",
    "    test_indexes_list = [s[1] for s in slices]\n",
    "\n",
    "    indexes = [idx[0] for idx in test_indexes_list]\n",
    "\n",
    "    trains = [y.loc[idx] for idx in train_indexes_list]\n",
    "    test = y.loc[indexes]\n",
    "\n",
    "    return trains, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(np.random.random(size=(len(dataset), 4)), columns=list('ABCD'))\n",
    "split_trains_test(\n",
    "    X, AnchoredSplitter(min_train_points=dataset.train_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"AIR_PASSENGERS\"\n",
    "dataset = DATASET_FACTORY_LOOKUP[dataset_name]()\n",
    "\n",
    "trains, test = split_trains_test(\n",
    "    dataset, AnchoredSplitter(min_train_points=dataset.train_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = fit_trains_and_predict_next(trains, test, model_class, params)\n",
    "\n",
    "results = metrics.generate_all_metrics(preds, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(\n",
    "    trial: optuna.Trial,\n",
    "    model_class: Type[models.OneAheadModel],\n",
    "    suggest_params: Callable[[optuna.Trial], dict],\n",
    "    train: pd.Series,\n",
    ") -> float:\n",
    "\n",
    "    parameters = suggest_params(trial)\n",
    "\n",
    "    trains, test = split_trains_test(train,\n",
    "                                     AnchoredSplitter(min_train_points=40))\n",
    "    preds = fit_trains_and_predict_next(trains, test, model_class, parameters)\n",
    "\n",
    "    trial.set_user_attr(\"metrics\", metrics.generate_all_metrics(preds, test))\n",
    "\n",
    "    return metrics.rmse(preds, test)\n",
    "\n",
    "\n",
    "def split_trains_test(\n",
    "    y: pd.Series,\n",
    "    splitter: Splitter,\n",
    ") -> Tuple[List[pd.Series], pd.Series]:\n",
    "\n",
    "    slices = splitter.split(y)\n",
    "\n",
    "    train_indexes_list = [s[0] for s in slices]\n",
    "    test_indexes_list = [s[1] for s in slices]\n",
    "\n",
    "    indexes = [idx[0] for idx in test_indexes_list]\n",
    "\n",
    "    trains = [y.loc[idx] for idx in train_indexes_list]\n",
    "    test = y.loc[indexes]\n",
    "\n",
    "    return trains, test\n",
    "\n",
    "\n",
    "def _predict(\n",
    "    model_class: Type[models.OneAheadModel],\n",
    "    parameters: dict,\n",
    "    train: dict,\n",
    ") -> float:\n",
    "    model = model_class(**parameters)\n",
    "    model.fit(train)\n",
    "    return model.predict_one_ahead()\n",
    "\n",
    "\n",
    "def fit_trains_and_predict_next(\n",
    "    trains: List[pd.Series],\n",
    "    test: pd.Series,\n",
    "    model_class: Type[models.OneAheadModel],\n",
    "    parameters: dict,\n",
    ") -> pd.Series:\n",
    "\n",
    "    partial_predict = partial(_predict, model_class, parameters)\n",
    "\n",
    "    preds = []\n",
    "    for train in tqdm(trains, ):\n",
    "        preds.append(partial_predict(train))\n",
    "\n",
    "    return pd.Series(preds, index=test.index, name=test.name)\n",
    "\n",
    "\n",
    "def tune_hyperparameters(\n",
    "    study_name: str,\n",
    "    model_class: Type[models.OneAheadModel],\n",
    "    train: pd.Series,\n",
    "    n_trials: int = 5,\n",
    ") -> optuna.trial.Trial:\n",
    "\n",
    "    study = optuna.create_study(\n",
    "        study_name=study_name,\n",
    "        direction=\"minimize\",\n",
    "        storage=\"sqlite:///optuna.db\",\n",
    "        load_if_exists=True,\n",
    "    )\n",
    "\n",
    "    partial_objective = partial(\n",
    "        objective,\n",
    "        model_class=model_class,\n",
    "        suggest_params=model_class.suggest_params,\n",
    "        train=train,\n",
    "    )\n",
    "    study.optimize(partial_objective, n_trials=n_trials)\n",
    "\n",
    "    return study.best_value, study.best_trial\n",
    "\n",
    "\n",
    "def train_and_test_model():\n",
    "    dataset_name = \"AIR_PASSENGERS\"\n",
    "\n",
    "    # model_name = \"RNN\"\n",
    "    # params = {\"epochs\": 700, \"hidden_units\": 25, \"timesteps\": 12}\n",
    "    # model_name = \"SARIMA\"\n",
    "    # params = {\"m\": 12}\n",
    "    # model_name = \"NAIVE\"\n",
    "    # params = {\"constant\": 0}\n",
    "    # model_name = \"ARIMA\"\n",
    "    # params = {}\n",
    "    model_name = \"SARIMA_SVR\"\n",
    "    params = {\"svr_C\": 0.011103136450426, \"svr_kernel\": \"linear\"}\n",
    "\n",
    "    filepath = f\"src/data/results/{dataset_name}_{model_name}_{uuid4().hex}.csv\"\n",
    "\n",
    "    dataset = DATASET_FACTORY_LOOKUP[dataset_name]()\n",
    "    model_class = ModelClassLookupCallback(model_name, dataset.period)\n",
    "\n",
    "    with mlflow.start_run():\n",
    "        trains, test = split_trains_test(\n",
    "            dataset, AnchoredSplitter(min_train_points=dataset.train_size))\n",
    "        preds = fit_trains_and_predict_next(trains, test, model_class, params)\n",
    "\n",
    "        results = metrics.generate_all_metrics(preds, test)\n",
    "\n",
    "        for metric_name, value in results.items():\n",
    "            mlflow.log_metric(metric_name, value)\n",
    "\n",
    "        mlflow.log_param(\"dataset_name\", dataset_name)\n",
    "        mlflow.log_param(\"model_name\", model_name)\n",
    "        mlflow.log_param(\"params\", params)\n",
    "        mlflow.log_param(\"n_train_points\", dataset.train_size)\n",
    "\n",
    "        preds.to_csv(filepath)\n",
    "        mlflow.log_artifact(filepath)\n",
    "\n",
    "    return metrics.rmse(preds, test)\n",
    "\n",
    "\n",
    "def get_best_study_params() -> dict:\n",
    "    dataset_name = \"AIR_PASSENGERS\"\n",
    "    model_name = \"SARIMA_SVR\"\n",
    "\n",
    "    study_name = f\"{dataset_name}/{model_name}/v2\"\n",
    "    study = optuna.create_study(\n",
    "        study_name=study_name,\n",
    "        direction=\"minimize\",\n",
    "        storage=\"sqlite:///optuna.db\",\n",
    "        load_if_exists=True,\n",
    "    )\n",
    "    print(study.best_params)\n",
    "    return study.best_params\n",
    "\n",
    "\n",
    "def tune_hyperparameters_with_optuna():\n",
    "    dataset_name = \"AIR_PASSENGERS\"\n",
    "    model_name = \"SARIMA_SVR\"\n",
    "\n",
    "    study_name = f\"{dataset_name}/{model_name}/v2\"\n",
    "\n",
    "    dataset = DATASET_FACTORY_LOOKUP[dataset_name]()\n",
    "    train = dataset.iloc[:dataset.train_size]\n",
    "\n",
    "    best_value, best_trial = tune_hyperparameters(\n",
    "        study_name=study_name,\n",
    "        model_class=ModelClassLookupCallback(model_name, dataset.period),\n",
    "        train=train,\n",
    "        n_trials=100,\n",
    "    )\n",
    "\n",
    "    print(best_value, best_trial.params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tune_hyperparameters_with_optuna()\n",
    "# get_best_study_params()\n",
    "# train_and_test_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel:\n",
    "\n",
    "    def __init__(self,\n",
    "                 timesteps: int,\n",
    "                 hidden_units: int,\n",
    "                 epochs: int,\n",
    "                 m: int = None):\n",
    "        self.model = None\n",
    "        self.timesteps = timesteps\n",
    "        self.hidden_units = hidden_units\n",
    "        self.epochs = epochs\n",
    "        self.x_input = None\n",
    "\n",
    "    def _create_model(self) -> keras.Sequential:\n",
    "        model = keras.Sequential()\n",
    "        model.add(\n",
    "            layers.SimpleRNN(\n",
    "                units=self.hidden_units,\n",
    "                activation=\"relu\",\n",
    "                input_shape=(self.timesteps, 1),\n",
    "            ))\n",
    "        model.add(layers.Dense(1))\n",
    "        model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "        return model\n",
    "\n",
    "    def fit(self, X: np.array, y: np.array) -> None:\n",
    "        self.model = self._create_model()\n",
    "        self.model.fit(X, y, epochs=self.epochs, verbose=0)\n",
    "\n",
    "    def predict_one_ahead(self) -> float:\n",
    "        return self.model.predict(self.x_input).reshape(-1)[0]\n",
    "\n",
    "    @staticmethod\n",
    "    def suggest_params(trial: optuna.Trial) -> dict:\n",
    "        timesteps = trial.suggest_categorical(\"timesteps\",\n",
    "                                              [2, 4, 6, 12, 24, 36])\n",
    "        hidden_units = trial.suggest_int(\"hidden_units\", 5, 25, 5)\n",
    "        epochs = trial.suggest_int(\"epochs\", 300, 800, 100)\n",
    "\n",
    "        return {\n",
    "            \"timesteps\": timesteps,\n",
    "            \"hidden_units\": hidden_units,\n",
    "            \"epochs\": epochs\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"AIR_PASSENGERS\"\n",
    "\n",
    "dataset = DATASET_FACTORY_LOOKUP[dataset_name]()\n",
    "model_class = HybridModel\n",
    "params = {\n",
    "    'first_model': SARIMAModel,\n",
    "    'second_model': RNNModel,\n",
    "    'first_model_params': {\n",
    "        \"m\": 12\n",
    "    },\n",
    "    'second_model_params': {\n",
    "        \"epochs\": 700,\n",
    "        \"hidden_units\": 25,\n",
    "        \"timesteps\": 12\n",
    "    },\n",
    "}\n",
    "\n",
    "trains, test = split_trains_test(\n",
    "    dataset, AnchoredSplitter(min_train_points=dataset.train_size))\n",
    "preds = fit_trains_and_predict_next(trains, test, model_class, params)\n",
    "\n",
    "results = metrics.generate_all_metrics(preds, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit ('3.9.12')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "df799a2a7b7efbb26e0d32ce1083bc8738f9f368b4708e77afccebbd088f12a4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
